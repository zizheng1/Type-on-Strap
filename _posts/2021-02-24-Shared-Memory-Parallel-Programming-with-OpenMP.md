---
layout: post
title: Shared-Memory Parallel Programming with OpenMP
tags: [OpenMP]
excerpt_separator: <!--more-->
---

<!--more-->


> This is the summary of Chapter 6 of Georg Hager and Gerhard Wellein's Introduction to High Performance Computing for Scientists and Engineers. This site is for EDUCATIONAL PURPOSES ONLY.

### Parallel Execution

OpenMP is a layer that adapts the raw OS thread interface to make it more usable with the typical structures that numerical software tends to employ. In practice, parallel regions in Fortran are initiated by `!OMP PARALLEL` and ended by `!OMP END PARALLEL` directives, respectively. The `!OMP` string is a so-called `sentinel`, which starts an OpenMP directive (in C/C++, `#pragma omp` is used instead). Inside a parallel region, each thread carries a unique identifier, its `thread ID`, which runs from zero to the number of threads minus one, and can be obtained by the `omp_get_thread_num()` API function:

```fortran
	use omp_lib ! module with API declarations

	print *,’I am the master, and I am alone’
!$OMP PARALLEL
	call do_work_package(omp_get_thread_num(),omp_get_num_threads())
!$OMP END PARALLEL
```

The `omp_get_num_threads()` function returns the number of active threads in the current parallel region. The `omp_lib` module contains the API definitions (in Fortran 77 and C/C++ there are include files `mpif.h` and `omp.h`, respectively).

An important difference between the Fortran and C/C++ OpenMP bindings must be stressed here. In C/C++, there is no `end parallel` directive, because all directives apply to the following statement or structured block. The example above would thus look like this in C++:

```c++
#include <omp.h>

std::cout << "I am the master, and I am alone";
#pragma omp parallel
{
	do_work_package(omp_get_thread_num(),omp_get_num_threads());
}
```

The curly braces could actually be omitted in this particular case, but the fact that a structed block is subject to parallel execution has consequences for data scoping. The actual number of running threads does not have to be known at compile time. It can be set by the environment variable prior to running the executable:

```sh
$ export OMP_NUM_THREADS=4
$ ./a.out
```

Although there are also means to set or alter the number of running threads under program control, an OpenMP program should always be written so that it does not assume a specific number of threads.

```fortran
	integer :: bstart, bend, blen, numth, tid, i
	integer :: N
	double precision, dimension(N) :: a,b,c
	...
!$OMP PARALLEL PRIVATE(bstart,bend,blen,numth,tid,i)
	numth = omp_get_num_threads()
	tid = omp_get_thread_num()
	blen = N/numth
	if(tid.lt.mod(N,numth)) then
		blen = blen + 1
		bstart = blen * tid + 1
	else
		bstart = blen * tid + mod(N,numth) + 1
	endif
	bend = bstart + blen - 1
	do i = bstart,bend
		a(i) = b(i) + c(i)
	enddo
!$OMP END PARALLEL
```

### Data Scoping

OpenMP supports this concept by defining a separate stack for every thread. There are three ways to make private variables:

1. A variable that exists before entry to a parallel construct can be privatized, i.e., made available as a private instance for every thread, by a `PRIVATE` clause to the `OMP PARALLEL` directive. The private variable’s scope extends until the end of the parallel construct.
2. The index variable of a worksharing loop (see next section) is automatically made private.
3. Local variables in a subroutine called from a parallel region are private to each calling thread. This pertains also to copies of actual arguments generated by the call-by-value semantics, and to variables declared inside structured blocks in C/C++. However, local variables carrying the `SAVE` attribute in Fortran (or the `static` storage class in C/C++) will be shared.

In C/C++, there is actually less need for using the `private` clause in many cases, because the `parallel` directive applies to a structured block. Instead of privatizing shared instances, one can simply declare local variables:

```fortran
#pragma omp parallel
{
	int bstart, bend, blen, numth, tid, i;
	... // calculate loop boundaries
	for(i=bstart; i<=bend; ++i)
	a[i] = b[i] + c[i];
}
```

### OpenMP Workingshare for Loops

As an example, consider a parallel version of a simple program for the calculation of $\pi$ by integration:

$$
	\pi = \int_0^1 dx\frac{4}{1+x^2}
$$

The initial value of `sum` is copied to the private instances via the `FIRSTPRIVATE` clause on the `PARALLEL` directive. Then, a `DO` directive in front of a `do` loop starts a worksharing construct. 

```fortran
	double precision :: pi,w,sum,x
	integer :: i,N=1000000

	pi = 0.d0
	w = 1.d0/N
	sum = 0.d0
!$OMP PARALLEL PRIVATE(x) FIRSTPRIVATE(sum)
!$OMP DO
	do i=1,n
 		x = w*(i-0.5d0)
 		sum = sum + 4.d0/(1.d0+x*x)
 	enddo
!$OMP END DO
!$OMP CRITICAL
	pi= pi + w*sum
!$OMP END CRITICAL
!$OMP END PARALLEL
```

If a separation of the parallel region from the workshared loop is not required, the two directives can be combined:

```fortran
!$OMP PARALLEL DO
	do i=1,N
		a(i) = b(i) + c(i) * d(i)
	enddo
!$OMP END PARALLEL DO
```

### Synchronization

Critical regions hold the danger of `deadlocks` when used inappropriately. A deadlock arises when one or more “agents” (threads in this case) wait for resources that will never become available, a situation that is easily generated with badly arranged `CRITICAL` directives. When a thread encounters a `CRITICAL` directive inside a critical region, it will block forever. Since this could happen in a deeply nested subroutine, deadlocks are sometimes hard to pin down.

OpenMP has a simple solution for this problem: A critical region may be given a name that distinguishes it from others. The name is specified in parentheses after the `CRITICAL` directive.

```fortran
!$OMP PARALLEL DO PRIVATE(x)
	do i=1,N
		x = SIN(2*PI*x/N)
!$OMP CRITICAL (psum)
		sum = sum + func(x)
!$OMP END CRITICAL (psum)
	enddo
!$OMP END PARALLEL DO
	...
	double precision func(v)
	double precision :: v
!$OMP CRITICAL (prand)
	func = v + random_func()
!$OMP END CRITICAL (prand)
	END SUBROUTINE func
```

The update to sum in line 5 is protected by a critical region. In subroutine `func()` there is another critical region because it is not allowed to call `random_func()` (line 13) by more than one thread at a time; it probably contains a random seed with a `SAVE` attribute. Such a function is not thread safe, i.e., its concurrent execution would incur a race condition.

### Barriers

If, at a certain point in the parallel execution, it is necessary to synchronize all threads, a `BARRIER` can be used:

```fortran
!$OMP BARRIER
```

The barrier is a *synchronization point*, which guarantees that all threads have reached it before any thread goes on executing the code below it. Certainly it must be ensured that every thread hits the barrier, or a deadlock may occur.

### Reductions

There is a set of supported operators for OpenMP reductions (slightly different for Fortran and C/C++), which cannot be extended. C++ overloaded operators are not allowed. However, the most common cases (addition, subtraction, multiplication, logical, etc.) are covered. 

```fortran
	double precision :: r,s
	double precision, dimension(N) :: a

	call RANDOM_SEED()
!$OMP PARALLEL DO PRIVATE(r) REDUCTION(+:s)
	do i=1,N
		call RANDOM_NUMBER(r) ! thread safe
		a(i) = a(i) + func(r) ! func() is thread safe
		s = s + a(i) * a(i)
	enddo
!$OMP END PARALLEL DO

	print *,’Sum = ’,s
```

### Loop Scheduling

As mentioned earlier, the mapping of loop iterations to threads is configurable. It can be controlled by the argument of a SCHEDULE clause to the loop worksharing directive:

```fortran
!$OMP DO SCHEDULE(STATIC)
	do i=1,N
		a(i) = calculate(i)
	enddo
!$OMP END DO
```

The simplest possibility is `STATIC`, which divides the loop into contiguous chunks of (roughly) equal size. Each thread then executes on exactly one chunk. If for some reason the amount of work per loop iteration is not constant but, e.g., decreases with loop index, this strategy is suboptimal because different threads will get vastly different workloads, which leads to load imbalance. One solution would be to use a *chunksize* like in “`STATIC,1`,” dictating that chunks of size 1 should be distributed across threads in a round-robin manner. The *chunksize* may not only be a constant but any valid integer-valued expression.

### Tasking

OpenMP 3.0 provides the *task* concept to circumvent this limitation. A task is defined by the `TASK` directive, and contains code to be executed.1 When a thread encounters a task construct, it may execute it right away or set up the appropriate data environment and defer its execution. The task is then ready to be executed later by any thread of the team.

As a simple example, consider a loop in which some function must be called for each loop index with some probability:

```fortran
	integer i,N=1000000
	type(object), dimension(N) :: p
	double precision :: r
	...
!$OMP PARALLEL PRIVATE(r,i)
!$OMP SINGLE
	do i=1,N
		call RANDOM_NUMBER(r)
		if(p(i)%weight > r) then
!$OMP TASK
! i is automatically firstprivate
! p() is shared
			call do_work_with(p(i))
!$OMP END TASK
		endif
	enddo
!$OMP END SINGLE
!$OMP END PARALLEL
```

The actual number of calls to `do_work_with()` is unknown, so tasking is a natural choice here. A `do` loop over all elements of `p()` is executed in a `SINGLE` region (lines 6–17). A `SINGLE` region will be entered by one thread only, namely the one that reaches the `SINGLE` directive first.